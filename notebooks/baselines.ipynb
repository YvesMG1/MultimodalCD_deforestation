{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Autoreload all modules ###\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "### Import libraries ###\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from skimage import filters\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "### Set base path ###\n",
    "base_path = Path(os.getcwd())\n",
    "while not (base_path / '.git').exists():\n",
    "    base_path = base_path.parent\n",
    "print('Base path: ', base_path)\n",
    "\n",
    "\n",
    "### Import custom modules ###\n",
    "sys.path.append(str(base_path / 'src/data/datasets/'))\n",
    "sys.path.append(str(base_path / 'src/training/'))\n",
    "sys.path.append(str(base_path / 'src/evaluation/'))\n",
    "sys.path.append(str(base_path / 'src/visualization/'))\n",
    "sys.path.append(str(base_path / 'src/models/'))\n",
    "\n",
    "from dataset import UkraineDataset\n",
    "from baselines import spatial_correction, nbr\n",
    "from pixel_metrics import ConfuseMatrixMeter\n",
    "from model_eval_plots import percentile_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = str(base_path / \"data/UKR/final_datasets/change_new/\")\n",
    "ukr_dataset = UkraineDataset(root_path, mode = \"test\", normalize = False,  return_cloud_mask = True, \n",
    "                 sentinel_type = \"S2\", indices = None, dilate_mask = True, bands = [1, 2, 3, 4, 5, 6, 7], file_type = \"tif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the dataset\n",
    "cm = ConfuseMatrixMeter(n_class=2)\n",
    "PLOT = False\n",
    "\n",
    "for i in range(len(ukr_dataset)):\n",
    "\n",
    "    imageA = ukr_dataset[i]['A'].numpy()\n",
    "    imageB = ukr_dataset[i]['B'].numpy()\n",
    "    mask = ukr_dataset[i]['mask'].numpy()\n",
    "    clouds_A = ukr_dataset[i]['cloud_mask_A'].numpy()\n",
    "    clouds_B = ukr_dataset[i]['cloud_mask_B'].numpy()\n",
    "    combined_cloud_mask = (clouds_A == 0) & (clouds_B == 0)\n",
    "\n",
    "    # calculate the euclidean distance\n",
    "    eu_distance = np.linalg.norm(imageA - imageB, axis = 0) \n",
    "    eu_distance = np.where(combined_cloud_mask, eu_distance, np.nan)\n",
    "\n",
    "    # apply thresholding\n",
    "    threshold = filters.threshold_otsu(eu_distance[~np.isnan(eu_distance)])\n",
    "    distance_binary = eu_distance > threshold\n",
    "\n",
    "    # apply spatial correction\n",
    "    distance_binary = spatial_correction(distance_binary, radius=3)\n",
    "\n",
    "    # pixel confusion matrix\n",
    "    temp_cm = confusion_matrix(mask.flatten(), distance_binary.flatten(), labels = [0, 1])\n",
    "    cm.update(temp_cm)\n",
    "\n",
    "    # perform percentile stretch on RG\n",
    "    rgb_A = np.stack([percentile_stretch(imageA[0], 1, 99), percentile_stretch(imageA[1], 1, 99), percentile_stretch(imageA[2], 1, 99)], axis = 0)\n",
    "    rgb_B = np.stack([percentile_stretch(imageB[0], 1, 99), percentile_stretch(imageB[1], 1, 99), percentile_stretch(imageB[2], 1, 99)], axis = 0)\n",
    "\n",
    "\n",
    "    if PLOT:\n",
    "        fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
    "        ax[0].imshow(rgb_A.transpose(1, 2, 0))\n",
    "        ax[1].imshow(rgb_B.transpose(1, 2, 0))\n",
    "        ax[2].imshow(mask)\n",
    "        ax[3].imshow(eu_distance)  \n",
    "        ax[4].imshow(distance_binary)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.804257033465432,\n",
       " 'miou': 0.4047117683375748,\n",
       " 'mf1': 0.4510365563011507,\n",
       " 'iou_0': 0.8040498057418598,\n",
       " 'iou_1': 0.005373730933289694,\n",
       " 'F1_0': 0.8913830982291331,\n",
       " 'F1_1': 0.01069001437316832,\n",
       " 'precision_0': 0.9990015792800022,\n",
       " 'precision_1': 0.005395739693488482,\n",
       " 'recall_0': 0.8046964455617224,\n",
       " 'recall_1': 0.5684896405283996}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfuseMatrixMeter(n_class=2)\n",
    "PLOT = False\n",
    "\n",
    "for i in range(len(ukr_dataset)):\n",
    "\n",
    "    imageA = ukr_dataset[i]['A'].numpy()\n",
    "    imageB = ukr_dataset[i]['B'].numpy()\n",
    "    mask = ukr_dataset[i]['mask'].numpy()\n",
    "    clouds_A = ukr_dataset[i]['cloud_mask_A'].numpy()\n",
    "    clouds_B = ukr_dataset[i]['cloud_mask_B'].numpy()\n",
    "    combined_cloud_mask = (clouds_A == 0) & (clouds_B == 0)\n",
    "\n",
    "    # calculate the NBR\n",
    "    nbr_A = nbr(imageA)\n",
    "    nbr_B = nbr(imageB)\n",
    "\n",
    "    # calculate absolute difference\n",
    "    distance = nbr_A - nbr_B \n",
    "    distance = np.where(combined_cloud_mask, distance, np.nan)\n",
    "\n",
    "    # apply thresholding\n",
    "    distance_binary = distance > 0.1\n",
    "\n",
    "    # apply spatial correction\n",
    "    distance_binary = spatial_correction(distance_binary, radius=1)\n",
    "\n",
    "    # pixel confusion matrix\n",
    "    temp_cm = confusion_matrix(mask.flatten(), distance_binary.flatten(), labels = [0, 1])\n",
    "    cm.update(temp_cm)\n",
    "\n",
    "    rgb_A = np.stack([percentile_stretch(imageA[0], 1, 99), percentile_stretch(imageA[1], 1, 99), percentile_stretch(imageA[2], 1, 99)], axis = 0)\n",
    "    rgb_B = np.stack([percentile_stretch(imageB[0], 1, 99), percentile_stretch(imageB[1], 1, 99), percentile_stretch(imageB[2], 1, 99)], axis = 0)\n",
    "\n",
    "    if PLOT:\n",
    "        fig, ax = plt.subplots(1, 6, figsize=(20, 5))\n",
    "        ax[0].imshow(rgb_A.transpose(1, 2, 0))\n",
    "        ax[1].imshow(rgb_B.transpose(1, 2, 0))\n",
    "        ax[2].imshow(nbr_A, cmap = \"RdYlGn\")\n",
    "        ax[3].imshow(nbr_B, cmap = \"RdYlGn\")\n",
    "        ax[4].imshow(mask)\n",
    "        ax[5].imshow(distance_binary)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9094604758902373,\n",
       " 'miou': 0.4605855649948816,\n",
       " 'mf1': 0.4879358270048154,\n",
       " 'iou_0': 0.909362412190966,\n",
       " 'iou_1': 0.011808717798797223,\n",
       " 'F1_0': 0.9525298598163014,\n",
       " 'F1_1': 0.023341794193329424,\n",
       " 'precision_0': 0.9991438731955551,\n",
       " 'precision_1': 0.011909896178207958,\n",
       " 'recall_0': 0.9100715368629497,\n",
       " 'recall_1': 0.5815945530402584}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.get_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
