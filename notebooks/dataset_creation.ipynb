{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Autoreload all modules ###\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "### Import necessary libraries ###\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### Set base path ###\n",
    "base_path = Path(os.getcwd())\n",
    "while not (base_path / '.git').exists():\n",
    "    base_path = base_path.parent\n",
    "print('Base path: ', base_path)\n",
    "\n",
    "\n",
    "### Import custom functions ###\n",
    "sys.path.append(str(base_path / 'src/data/preprocessing'))\n",
    "sys.path.append(str(base_path / 'src/visualization'))\n",
    "\n",
    "from utils import get_files, parse_filename, load_mask\n",
    "from preprocessing_plots import plot_images\n",
    "from create_dataset import run_clustering, copy_to_final_directory, compute_stats_for_bands, create_datasets\n",
    "from histogram_eval import compute_histograms, compute_average_histograms, calculate_wasserstein_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mask_dir = '/scratch/yves/Thesis/Yves-MSc-Thesis/data/UKR/filtered/diff_masks'\n",
    "clusters, features, data = run_clustering(diff_mask_dir, nclusters = 8, mask_type='diff_mask', random_state = 30)\n",
    "\n",
    "print(\"Uniquce clusters: \", np.unique(clusters, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6), sharey=True, sharex=True)\n",
    "unique_clusters = np.unique(clusters)\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, len(unique_clusters) + 1))  \n",
    "\n",
    "cluster_assignments = {\n",
    "    'training': [1, 3, 5, 7],  # 398\n",
    "    'validation': [0, 4],      # 161\n",
    "    'test': [2, 6]             # 134\n",
    "}\n",
    "\n",
    "y_min = np.min(features[:, 1])\n",
    "y_max = np.max(features[:, 1])\n",
    "\n",
    "titles = ['36UXA', '36UYA']\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    mask = features[:, 2] == i\n",
    "    cluster_colors = [colors[unique_clusters.tolist().index(cl)] for cl in clusters[mask]]\n",
    "    ax.scatter(features[mask, 0], features[mask, 1], c=cluster_colors, alpha=0.5)\n",
    "    ax.set_title(f'Tile {titles[i]}')\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim(y_max, y_min)\n",
    "    \n",
    "for uc in unique_clusters:\n",
    "    assignment_key = [k for k, v in cluster_assignments.items() if uc in v]\n",
    "    axes[0].scatter([], [], color=colors[unique_clusters.tolist().index(uc)], label=f'{uc}: {assignment_key[0]}')\n",
    "\n",
    "axes[0].legend(title='Clusters')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/validation/test set assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valtest_dates = [\"20170909\", \"20180601\", \"20180616\", \"20180815\", \"20190606\", \"20160731\", \"20190407\", \"20190606\", \"20190701\", \"20190904\"]\n",
    "train_dates = [\"20170825\", \"20171909\", \"20180422\", \"20180508\", \"20180731\", \"20180830\", \"20180919\", \"20190427\", \"20160522\", \"20160830\", \"20190517\", \"20190611\", \"20190616\", \"20190820\", \"20190909\"]\n",
    "\n",
    "train_data, test_data, val_data, df = create_datasets(diff_mask_dir, cluster_assignments, clusters, data, train_dates, valtest_dates, mask_type='diff_mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the val/test/train distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deforestation change distribution of train, val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axs[0].hist(train_data[\"Deforestation\"], bins=20, alpha=0.5, color='b', label='Train', density=True)\n",
    "axs[0].hist(val_data[\"Deforestation\"], bins=20, alpha=0.5, color='r', label='Validation', density=True)\n",
    "axs[0].hist(test_data[\"Deforestation\"], bins=20, alpha=0.5, color='g', label='Test', density=True)\n",
    "axs[0].set_xlabel('Deforestation change (in pixels)')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].set_title('Deforestation change (# of pixels per mask, all locations)')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].hist(train_data[train_data['Deforestation'] > 0][\"Deforestation\"], bins=20, alpha=0.5, color='b', label='Train', density=True)\n",
    "axs[1].hist(val_data[val_data['Deforestation'] > 0][\"Deforestation\"], bins=20, alpha=0.5, color='r', label='Validation', density=True)\n",
    "axs[1].hist(test_data[test_data['Deforestation'] > 0][\"Deforestation\"], bins=20, alpha=0.5, color='g', label='Test', density=True)\n",
    "axs[1].set_xlabel('Deforestation change (in pixels)' )\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].set_title('Deforestation change (# of pixels per mask, excl. locations with no change)')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud cover distribution of train, val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axs[0].hist(train_data[\"Cloud1\"]*100 + train_data[\"Cloud2\"]*100, bins=20, alpha=0.5, color='b', label='Train', density=True)\n",
    "axs[0].hist(val_data[\"Cloud1\"]*100 + val_data[\"Cloud2\"]*100, bins=20, alpha=0.5, color='r', label='Validation', density=True)\n",
    "axs[0].hist(test_data[\"Cloud1\"]*100 + test_data[\"Cloud2\"]*100, bins=20, alpha=0.5, color='g', label='Test', density=True)\n",
    "axs[0].set_xlabel('Cloud cover in %')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].set_title('Cloud cover (date A + date B per location, all locations)')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].hist(train_data[train_data['Cloud1'] > 0][\"Cloud1\"]*100 + train_data[train_data['Cloud2'] > 0][\"Cloud2\"]*100, bins=20, alpha=0.5, color='b', label='Train', density=True)\n",
    "axs[1].hist(val_data[val_data['Cloud1'] > 0][\"Cloud1\"]*100 + val_data[val_data['Cloud2'] > 0][\"Cloud2\"]*100 , bins=20, alpha=0.5, color='r', label='Validation', density=True)\n",
    "axs[1].hist(test_data[test_data['Cloud1'] > 0][\"Cloud1\"]*100 + test_data[test_data['Cloud2'] > 0][\"Cloud2\"]*100, bins=20, alpha=0.5, color='g', label='Test', density=True)\n",
    "axs[1].set_xlabel('Cloud cover in %')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].set_title('Cloud cover (date A + date B per location, excl. locations with no clouds)')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Season / year-type distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "cats = ['Season1', 'Season2', 'Year Type']\n",
    "titles = ['Season distribution of Image A', 'Season distribution of Image B', 'Year type distribution between A and B']\n",
    "\n",
    "for i in range(len(cats)):\n",
    "    train_percent = train_data[cats[i]].value_counts(normalize=True) * 100\n",
    "    val_percent = val_data[cats[i]].value_counts(normalize=True) * 100\n",
    "    test_percent = test_data[cats[i]].value_counts(normalize=True) * 100\n",
    "\n",
    "    all_categories = set(train_percent.index) | set(val_percent.index) | set(test_percent.index)\n",
    "    \n",
    "    train_percent = train_percent.reindex(all_categories, fill_value=0)\n",
    "    val_percent = val_percent.reindex(all_categories, fill_value=0)\n",
    "    test_percent = test_percent.reindex(all_categories, fill_value=0)\n",
    "\n",
    "    x = range(len(all_categories)) \n",
    "    width = 0.25 \n",
    "\n",
    "    axs[i].bar(x, train_percent, width=width, color='b', alpha=0.5, label='Train')\n",
    "    axs[i].bar([p + width for p in x], val_percent, width=width, color='r', alpha=0.5, label='Validation')\n",
    "    axs[i].bar([p + width*2 for p in x], test_percent, width=width, color='g', alpha=0.5, label='Test')\n",
    "    axs[i].set_xlabel(cats[i])\n",
    "    axs[i].set_ylabel('Percentage')\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].set_xticks([p + width for p in x])\n",
    "    axs[i].set_xticklabels(list(all_categories))\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the dataset to the final destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mask_dir = str(base_path / 'data/UKR/filtered/diff_masks')\n",
    "final_dir = str(base_path / 'data/UKR/final_datasets/change_test')\n",
    "train_final_dir = os.path.join(final_dir, 'train')\n",
    "val_final_dir = os.path.join(final_dir, 'val')\n",
    "test_final_dir = os.path.join(final_dir, 'test')\n",
    "\n",
    "copy_to_final_directory(train_data, diff_mask_dir, train_final_dir, split_type='train', save_format='tif')\n",
    "copy_to_final_directory(val_data, diff_mask_dir, val_final_dir, split_type='val', save_format='tif')\n",
    "copy_to_final_directory(test_data, diff_mask_dir, test_final_dir, split_type='test', save_format='tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_files_dir = str(base_path / 'data/UKR/final_datasets/change_new/train')\n",
    "save_path = str(base_path / 'data/UKR/final_datasets/change_new/percentiles/train')\n",
    "\n",
    "stats = compute_stats_for_bands(images_files_dir, save = False, save_path = save_path, percentiles = [0, 100],\n",
    "                               return_values = True, file_type='tif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
